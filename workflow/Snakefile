# The main entry point of your workflow.
# Run from root dir (parent dir of this Snakefile)
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.

# --------------
# Configuration
# --------------
configfile: "workflow/config/main.yaml"
report: "workflow/report/workflow.rst"

# Allow users to fix the underlying OS via singularity.
singularity: "docker://continuumio/miniconda3"

# --------------
# Target file
# --------------

# --------------
# Rules
# --------------
rule get_data_profile:
    input:
        "data/app{app_id}/ukb{data_id}.html"
    output:
        "data/app{app_id}/ukb{data_id}.profile.tsv"
    script:
        "scripts/parse_html.R"

rule split_by_type:
    input:
        data="data/app{app_id}/ukb{data_id}.csv",
        profile="data/app{app_id}/ukb{data_id}.profile.csv"
    output:
        "data/app{app_id}/ukb{data_id}_{type}_wide.csv"
    shell:
        """
        awk -F, -vOFS=, -vFPAT='([^,]*)|("[^"]+")' -vTYPE={wildcards.type} '
            NR==FNR {{if ($1 == "eid" || $6 == TYPE) {{count++; a[count]=$1+1}}; next}}
            {{for (i=1; i<=count; i++) printf "%s%s", $a[i], i==count?ORS:OFS}}
        ' {input.profile} {input.data} > {output}
        """

rule transform_wide_to_long:
    input:
        "data/app{app_id}/ukb{data_id}_{type}_wide.csv"
    output:
        "data/app{app_id}/ukb{data_id}_{type}_long.csv"
    script:
        "scripts/wide_to_long.R"

rule make_db:
    input:
        data=expand("data/app{app_id}/ukb{data_id}.csv",
                    app_id=['15422'], data_id=['42306']),
        profile=expand("data/app{app_id}/ukb{data_id}.profile.csv",
                       app_id=['15422'], data_id=['42306'])
    output:
        db="data/ukb.sqlite"
    script:
        "scripts/make_db.R"



# --------------
# Load rules
# --------------
include: "rules/phenotyping.smk"
